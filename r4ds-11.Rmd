---
title: "r4ds: 11"
output: 
  html_notebook:
    toc: true
    highlight: kate
---

# 11 Data Import

From R for Data Science: [11 Data Import](http://r4ds.had.co.nz/data-import.html)
Started: 1 May, 2018
Completed: 2 May, 2018

## 11.1 Introduction

```{r}
library(tidyverse)
```

## 11.2 Getting Started

- `readr` functions are mostly concerned with flat files into data.frames:

|separation|function    
|:--------|:-----------|
|delimiter| |
| , comma | `read_csv()` |
| ; semi-colon | `read_csv2()`|
| tab | `read_tcv()` |
| other | `read_delim()` |
|fixed width files| |
| auto | `read_fwf()` |
| widths | `fwf_width()` |
| positions | `fwf_positions()` |
|other| |
|white space table| `read_table()` |
|log files| `read_log()` or [webreadr](https://github.com/Ironholds/webreadr)

- Focus on `?read_csv`. Use inline csv for experimentation
    - `comment = "#"` drops all lines starting with `#`
    - `skip = n` skips n lies, after comment drop (regardless of order in function)
    - `col_names = TRUE/FALSE/c(vector)`
    - `na = "."` reads any `.` in the csv as N/A values 

```
read_csv(
  "# comment
  meta data
  a,b,c
  1,2,3
  4,5,6",
  skip = 1, comment = "#", col_names = c("one","two","three")
)

#   A tibble: 3 x 3
#   one   two   three
#   <chr> <chr> <chr>
# 1 a     b     c    
# 2 1     2     3    
# 3 4     5     6    
```
)

### 11.2.1 Compared to Base R

- many reasons readr is better

### 11.2.2 Exercises

1. delimiter `|`

```{r}
read_delim(
  "a|b|c\n1|2|3\n4|5|6",
  "|"
)
```

2. Common options to `read_csv()` and `read_tsv()`: EVERYTHING
    - `file`, `skip`, `comment`
    - `col_names`, `col_types`, 
    - `locale = default_locale()` controls default timezone, encoding etc.
    - `na = c("",".","NA")`, `quoted_na = TRUE`,
    - `quote`, `comment` characters used to quote strings, and mark comments,
    - `trim_ws = TRUE` removes leading and trailing whitespace
    - `skip = n` skips lines before reading data
    - `n_max`, `guess_max` maximums rows to read, rows to use to guess col type
    - `progress`
    
3. Most important options to `?read_fwf`
    - file
    - col positions generated by `fwf_positions`, `fwf_empty` etc.
    
```
fwf_sample <- readr_example("fwf-sample.txt")
cat(read_lines(fwf_sample))
# You can specify column positions in several ways:
# 1. Guess based on position of empty columns
read_fwf(fwf_sample, fwf_empty(fwf_sample, col_names = c("first", "last", "state", "ssn")))
# 2. A vector of field widths
read_fwf(fwf_sample, fwf_widths(c(20, 10, 12), c("name", "state", "ssn")))
# 3. Paired vectors of start and end positions
read_fwf(fwf_sample, fwf_positions(c(1, 30), c(10, 42), c("name", "ssn")))
# 4. Named arguments with start and end positions
read_fwf(fwf_sample, fwf_cols(name = c(1, 10), ssn = c(30, 42)))
# 5. Named arguments with column widths
read_fwf(fwf_sample, fwf_cols(name = 20, state = 10, ssn = 12))
```

4. Read this: `"x,y\n1,'a,b'"` into a data frame

```
read_csv(
  "x,y\n1,'a,b'",
  quote = "'")

# A tibble: 1 x 2
#       x y    
#   <int> <chr>
# 1     1 a,b  
```

5. Whats wrong with:

- `read_csv("a,b\n1,2,3\n4,5,6")`: missing col name; only keeps col 1 & 2 values
- `read_csv("a,b,c\n1,2\n1,2,3,4")`: only keeps 3 cols, inputs NA, and drops 4
- `read_csv("a,b\n\"1")`: inputs NA for missing value
- `read_csv("a,b\n1,2\na,b")`: 
- `read_csv("a;b\n1;3")`: delimiter is semi-colon, should be `read_csv2`

## 1.3 Parsing a vector

`parse_*()`:

```
str(parse_logical(c("TRUE", "FALSE", "NA")))
#>  logi [1:3] TRUE FALSE NA
str(parse_integer(c("1", "2", "3")))
#>  int [1:3] 1 2 3
parse_integer(c("1", "231", ".", "456"), na = ".")
#> [1]   1 231  NA 456
str(parse_date(c("2010-01-01", "1979-10-14")))
#>  Date[1:2], format: "2010-01-01" "1979-10-14"
```

**`parse_*()` Failures:**

```
x <- parse_integer(c("123", "345", "abc", "123.45"))
problems(x)
```

### 11.3.1 Numbers

**Functions**:

- `parse_integer()`: no fractions or decimals
- `parse_double()`: strict
- `parse_number()`: flexible

**Issues**:

1. different formats/styles around the world. e.g. demicals as `,` or `.`
    - locale: `parse_double("1,23", locale = locale(decimal_mark = ","))`
2. context charaters: `$` or `%`, and groupings: `1,000,000`
    - `parse_number()` ignores non-numeric characters 
    
### 11.3.2 Strings

- `parse_character()` uses UTF-8 as default encoding
- use `guess_encoding(x)` to guess, or look in documentation
- more information: http://kunststube.net/encoding/

```
x1 <- "El Ni\xf1o was particularly bad this year"
x2 <- "\x82\xb1\x82\xf1\x82\xc9\x82\xbf\x82\xcd"

## if encoding is known
parse_character(x1, locale = locale(encoding = "Latin1"))
parse_character(x2, locale = locale(encoding = "Shift-JIS"))
# [1] "El Niño was particularly bad this year"
# [1] "こんにちは"


## guess encoding using readr
guess_encoding(charToRaw(x1))
# # A tibble: 2 x 2
#   encoding   confidence
#   <chr>           <dbl>
# 1 ISO-8859-1       0.46
# 2 ISO-8859-9       0.23
parse_character(x1, locale = locale(encoding = "ISO-8859-1"))
# [1] "El Niño was particularly bad this year"
parse_character(x1, locale = locale(encoding = "ISO-8859-2"))
# [1] "El Nińo was particularly bad this year"

## guesses don't always work
guess_encoding(charToRaw(x2))
# # A tibble: 1 x 2
#   encoding confidence
#   <chr>         <dbl>
# 1 KOI8-R         0.42
parse_character(x2, locale = locale(encoding = "KOI8-R"))
# [1] "┌╠┌Я┌и┌©┌м"
```

### 11.3.3 Factors

- factors represent known categorical variables
- `levels` stores known possible values
- `parse_factor(x, levels)` checks input against levels and warns

```{r}
fruit <- c("apple", "banana")
parse_factor(c("apple", "banana", "bananana"), levels = fruit)
```

### 11.3.4 Dates, date-times, and times

**Functions**
- `parse_datetime()`:
    - default format expected is [ISO8601](https://en.wikipedia.org/wiki/ISO_8601)
    - big to small: year, month, day, hour, minute
- `parse_date()` 
    - default expectation: `%Y[-/]%m[-/]%d`
- `parse_time()`
    - hour `:` minutes (`:` seconds `am/pm`)

**Custom Formats**

|Year         |Month        |Day          |
|-------------|-------------|-------------|
|`%Y` (yyyy)    |`%m` (mm)      |`%d` (dd)      |
|`%y` (yy);\n 00-69 -> 2000-2069 |`%b` (abrv: “Jan”)|`%e` (opt. leading space)
| |`%B` (full name, “January”).| |

|Hour                        |Minutes, Seconds|Time zone|
|----------------------------|----------------|---------|
`%H` 0-23 hour                 |`%M` minutes      |`%z` (America/Chicago) |
`%I` 0-12, with %p             |`%S` integer secs |`%z` (+0800 from UTC)  |
`%p` AM/PM indicator           |`%OS` real secs   |

`%.` skips one non-digit
`%*` skips consectutive non-digit

The best way to figure out the correct format is to create a few examples in a character vector, and test with one of the parsing functions. For example:

```
parse_date("01/02/15", "%m/%d/%y")
#> [1] "2015-01-02"
parse_date("01/02/15", "%d/%m/%y")
#> [1] "2015-02-01"
parse_date("01/02/15", "%y/%m/%d")
#> [1] "2001-02-15"
```

Localisation:
```
parse_date("1 janvier 2015", "%d %B %Y", locale = locale("fr"))
# [1] "2015-01-01"
```



### 11.3.5 Exercises

1. Locale arguments; see `?locale()` for list; `vignette("locales")` for examples:
- `date_names = "en" or "fr"`
- `date_format`, `time_format`
- `decimal_mark`, `grouping_mark`
- `tz`: timezone list `OlsonNames()`; avoid `tz = ""` system default
- `encoding = "UTF-8"`
- `asciify`: for removal of diacritics

2. what happens:
```
## returns error `decimal_mark` and `grouping_mark` must be different:
#parse_double("1,23", locale = locale(decimal_mark = ",", grouping_mark = ","))
# changes default grouping_mark to ".":
parse_double("1100,23", locale = locale(decimal_mark = ","))
```

3. `date_format`, `time_format`


```{r}
str(parse_guess("2012-10-23", locale = locale(date_format = "%Y-%m-%d")))
```

4. !!! `locale()` if outside of US

5. `read_csv()`: commas, `read_csv`: semi-colons separate values

6. !!! Common Encodings in Asia, Europe?

7. Generate correct format string to parse date and time:

```
d1 <- "January 1, 2010"
parse_date(d1,format = "%B%e, %Y")
# [1] "2010-01-01"

d2 <- "2015-Mar-07"
parse_date(d2,"%Y-%b-%d")
# [1] "2015-03-07"

d3 <- "06-Jun-2017"
parse_date(d3,format = "%d-%b-%Y")
# [1] "2017-06-06"

d4 <- c("August 19 (2015)", "July 1 (2015)")
parse_date(d4,"%B %d (%Y)")
# [1] "2015-08-19" "2015-07-01"

d5 <- "12/30/14" # Dec 30, 2014
parse_date(d5,"%m/%d/%y")
# [1] "2014-12-30"

t1 <- "1705"
parse_time(t1, "%H%M")
# 17:05:00

t2 <- "11:15:10.12 PM"
parse_time(t2, "%I:%M:%OS %p")
# 23:15:10.12
```

## 11.4 Parsing a File

### 11.4.1 Strategy

readr guesses using first 1000 rows. `guess_parser`:
    - stop if match in this order: logical > integer > double > number > time (`time_format`) > date (`date_format`) > date-time (`ISO8601`) > string

### 11.4.2 Problems

defaults can fail if first 1000:
    - special cases (e.g. x = dbl, but [1:1000,x] = int)
    - contain lots of missing values (e.g. [1:1000,x] = "NA" reads as "character")
    
```{r}
# Illustration of problems

challenge <- read_csv(readr_example("challenge.csv"))
# default: x = <int>, y = <chr>
stop_for_problems(challenge) # returns error, useful for automated scripts
problems(challenge)
# <dbl> values in x are parsed as "NA"

## correct x : <int> to <dbl>
challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double()
  )
)
# y still <chr>

## checking col type if no parse error:

# show no. obs, variables, and head of var as row vectors
glimpse(challenge)
# see end values of all variables
tail(challenge)
# list distinct values of variable
distinct(challenge, x)

## correct parsing:
challenge <- read_csv(
  readr_example("challenge.csv"), 
  col_types = cols(
    x = col_double(),
    y = col_date()
  )
)
```

## Other strategies

- increase max guess range: `read_*(x, guess_max = 1001)`
- read in as character vectors for:
    - easier diagnosis: `glimpse()` `tail()` `distinct()` 
    - regex clean up: 
    - parse again: (`type_convert()`)
- for large datasets set `n_max` to small number like 10,000, to acclerate diagnosis iterations
- use `read_lines` or `read_file`, then use string parsing skills

```
challenge2 <- read_csv(readr_example("challenge.csv"), 
  col_types = cols(.default = col_character())
)
glimpse(challenge2)

## useful for manual munging, read as character, regex clean, then parse again
type_convert(challenge2)
```

## 11.5 Writing to a file

**CSV**

- `write_csv(x, [path])` or `write_tsv()`
- string encoding: UTF-8
- dates, date-times: ISO8601
- for Excel: `write_excel_csv()`
- LOSE type information when saving to csv

**RDS: R custom binary format**

```
write_rds(challenge, "challenge.rds")
read_rds("challenge.rds")
#> # A tibble: 2,000 × 2
#>       x      y
#>   <dbl> <date>
#> 1   404   <NA>
#> 2  4172   <NA>
#> 3  3004   <NA>
#> 4   787   <NA>
#> 5    37   <NA>
#> 6  2332   <NA>
#> # ... with 1,994 more rows
```

**feather: shareable across prog. lang**

- doesn't support list columns

```
library(feather)
write_feather(challenge, "challenge.feather")
read_feather("challenge.feather")
#> # A tibble: 2,000 x 2
#>       x      y
#>   <dbl> <date>
#> 1   404   <NA>
#> 2  4172   <NA>
#> 3  3004   <NA>
#> 4   787   <NA>
#> 5    37   <NA>
#> 6  2332   <NA>
#> # ... with 1,994 more rows
```

## 11.6 Other types of data

- `haven::`: SPSS, Stata, SAS
- `readxl::`: `.xls` and `.xlsx`
- `DBI::`: allows for SQL queries
- `jsonlite::` or `xml2`: hierarchical data
- worked exampels: https://jennybc.github.io/purrr-tutorial/
- other file types: [R data import/export manual](https://cran.r-project.org/doc/manuals/r-release/R-data.html)

```

